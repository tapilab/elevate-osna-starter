{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See instructions here:\n",
    "\n",
    "https://github.com/tapilab/elevate-osna-starter/blob/master/lessons/week3/README.md#day-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@FlyGuyCree Nigga whatever one you gave me ü§¶üèª‚Äç‚ôÄÔ∏è</td>\n",
       "      <td>nonhostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ArvindKejriwal . go to hell you ass hole.</td>\n",
       "      <td>hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@JohnJohnDaDon That ‚Äúnigga‚Äù done lost his fuck...</td>\n",
       "      <td>hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kane_tingle10 Can‚Äôt be fucked with them mate....</td>\n",
       "      <td>nonhostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@JHarris_TheDon Its honestly better anyways. T...</td>\n",
       "      <td>nonhostile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0   @FlyGuyCree Nigga whatever one you gave me ü§¶üèª‚Äç‚ôÄÔ∏è  nonhostile\n",
       "1         @ArvindKejriwal . go to hell you ass hole.     hostile\n",
       "2  @JohnJohnDaDon That ‚Äúnigga‚Äù done lost his fuck...     hostile\n",
       "3  @kane_tingle10 Can‚Äôt be fucked with them mate....  nonhostile\n",
       "4  @JHarris_TheDon Its honestly better anyways. T...  nonhostile"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(datafile):\n",
    "    \"\"\"\n",
    "    Read your data into a single pandas dataframe where\n",
    "    - each row is an instance to be classified\n",
    "    (this could be a tweet, user, or news article, depending on your project)\n",
    "    - there is a column called `label` which stores the class label (e.g., the true\n",
    "      category for this row)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(datafile)[['text', 'hostile']]\n",
    "    df.columns = ['text', 'label']\n",
    "    df['label'] = ['hostile' if i==1 else 'nonhostile' for i in df.label]\n",
    "    return df\n",
    "\n",
    "df = load_data('~/Dropbox/elevate/harassment/training_data/data.csv.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hostile       3588\n",
       "nonhostile    3186\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution over class labels?\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    vec = DictVectorizer()\n",
    "    feature_dicts = []\n",
    "    # just as an initial example, we will consider three\n",
    "    # word features in the model.\n",
    "    words_to_track = ['you', 'hate', 'love']\n",
    "    # will get different model for different features.\n",
    "    #words_to_track = ['you']\n",
    "    for i, row in df.iterrows():\n",
    "        features = {}\n",
    "        token_counts = Counter(re.sub('\\W+', ' ', row['text'].lower()).split())\n",
    "        for w in words_to_track:\n",
    "            features[w] = token_counts[w]\n",
    "        feature_dicts.append(features)\n",
    "    X = vec.fit_transform(feature_dicts)\n",
    "    return X, vec\n",
    "                \n",
    "X, vec = make_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6774x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1933 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6774, 21018)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, use CountVectorizer to create a term feature matrix.\n",
    "count_vec = CountVectorizer(min_df=1)\n",
    "X_words = count_vec.fit_transform(df.text)\n",
    "X_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 the\t2716\n",
      "                 you\t2622\n",
      "               nigga\t2340\n",
      "                  to\t1918\n",
      "                 and\t1691\n",
      "                that\t1641\n",
      "                  it\t1232\n",
      "                  is\t1221\n",
      "                shit\t1184\n",
      "                  of\t1091\n"
     ]
    }
   ],
   "source": [
    "# top terms?\n",
    "def print_top_words(X_words, count_vec, n=10):\n",
    "    features = count_vec.get_feature_names()\n",
    "    word_counts = X_words.sum(axis=0).A1\n",
    "    for i in np.argsort(word_counts)[::-1][:n]:\n",
    "        print('%20s\\t%d' % (features[i], word_counts[i]))\n",
    "\n",
    "print_top_words(X_words, count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'nonhostile': 3186, 'hostile': 3588})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll first store the classes separately in a numpy array\n",
    "y = np.array(df.label)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the class names\n",
    "class_names = set(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6774, 21021)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = hstack([X, X_words]).tocsr()\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a LogisticRegression classifier.\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "clf.fit(X_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.13452078, -0.68387522,  0.14541614, ...,  0.06153179,\n",
      "        0.06153179,  0.06153179]), array([ 0.13452078,  0.68387522, -0.14541614, ..., -0.06153179,\n",
      "       -0.06153179, -0.06153179])]\n"
     ]
    }
   ],
   "source": [
    "# for binary classification, the coefficients for the negative class is just the negative of the positive class.\n",
    "coef = [-clf.coef_[0], clf.coef_[0]]\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hostile', 'nonhostile'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all cross-validation folds: [0.5424354243542435, 0.5476014760147602, 0.5276752767527675, 0.5402214022140222, 0.5236336779911374]\n",
      "mean=0.54 std=0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train, test in kf.split(X):\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred = clf.predict(X[test])\n",
    "    accuracies.append(accuracy_score(y[test], pred))\n",
    "    \n",
    "    \n",
    "print('accuracy over all cross-validation folds: %s' % str(accuracies))\n",
    "print('mean=%.2f std=%.2f' % (np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(vec.get_feature_names() + count_vec.get_feature_names())\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hostile'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nigga\n",
      "0.19077783360160389\n",
      "you\n",
      "0.14541613571878462\n",
      "you\n",
      "0.14541613571878462\n",
      "gave\n",
      "-0.020392695987220318\n",
      "flyguycree\n",
      "-0.16244314389468142\n",
      "me\n",
      "-0.21987134662842517\n",
      "whatever\n",
      "-0.29767900360130367\n",
      "one\n",
      "-0.4465985350915529\n"
     ]
    }
   ],
   "source": [
    "# why was the first example labeled hostile?\n",
    "for i in np.argsort(coef[0][X_all[0].nonzero()[1]])[::-1]:\n",
    "    idx = X_all[0].nonzero()[1][i]\n",
    "    print(features[idx])\n",
    "    print(coef[0][idx])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
